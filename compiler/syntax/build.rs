#![feature(iter_intersperse)]

use std::{
	path::{Path, PathBuf},
	process::Command,
};

use quote::{
	__private::{Ident, TokenStream}, // I'm sorry.
	format_ident,
	quote,
};
use ungrammar::{Grammar, Rule};

fn main() {
	println!("cargo:rerun-if-changed=yam.ungram");
	let grammar: Grammar = std::fs::read_to_string("yam.ungram").unwrap().parse().unwrap();

	let out: PathBuf = (std::env::var("CARGO_MANIFEST_DIR").unwrap() + "/src/generated/").into();
	Generator::new(&grammar).generate(&out);
}

struct Generator<'a> {
	grammar: &'a Grammar,
	token_kinds: Vec<Ident>,
	node_kinds: Vec<Ident>,
	tokens: Vec<TokenStream>,
	nodes: Vec<TokenStream>,
}

impl<'a> Generator<'a> {
	fn new(grammar: &'a Grammar) -> Self {
		Self {
			grammar,
			token_kinds: Vec::new(),
			node_kinds: Vec::new(),
			tokens: Vec::new(),
			nodes: Vec::new(),
		}
	}

	fn generate(mut self, out: &Path) {
		self.gen_kinds();
		self.gen_tokens();
		self.gen_ast();

		let Generator {
			token_kinds,
			node_kinds,
			tokens,
			nodes,
			..
		} = self;

		let kind = (quote! {
			#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
			#[repr(u16)]
			pub enum SyntaxKind {
				/// Terminal tokens
				#(#token_kinds,)*

				/// Non-terminal nodes
				#(#node_kinds,)*

				#[doc(hidden)]
				/// Always keep last, is not actually allowed to appear anywhere.
				__Last,
			}
		})
		.to_string();
		let kind = "// This file is generated by build.rs\n// Do not edit\n\n".to_string() + &kind;
		write(out.join("kind.rs"), kind);

		let token = std::iter::once(
			"// This file is generated by build.rs\n// Do not edit\n\nuse crate::generated::*;\n\n".to_string(),
		)
		.chain(
			tokens
				.into_iter()
				.map(|t| t.to_string())
				.intersperse("\n\n".to_string()),
		)
		.collect();
		write(out.join("token.rs"), token);

		let ast = std::iter::once(
			"// This file is generated by build.rs\n// Do not edit\n\nuse crate::{*, generated::*, token::*};\n\n"
				.to_string(),
		)
		.chain(nodes.into_iter().map(|t| t.to_string()).intersperse("\n\n".to_string()))
		.collect();
		write(out.join("ast.rs"), ast);
	}

	fn gen_kinds(&mut self) {
		self.token_kinds = self
			.grammar
			.tokens()
			.map(|n| format_ident!("{}", map_token(&self.grammar[n].name)))
			.collect();

		self.node_kinds = self
			.grammar
			.iter()
			.map(|n| {
				let node = &self.grammar[n];
				format_ident!("{}", node.name)
			})
			.collect();
	}

	fn gen_tokens(&mut self) {
		self.tokens = self
			.grammar
			.tokens()
			.map(|n| {
				let ident = format_ident!("{}", map_token(&self.grammar[n].name));

				quote! {
					#[derive(Clone, PartialEq, Eq, Hash)]
					pub struct #ident(SyntaxToken);

					impl std::fmt::Debug for #ident {
						fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
							std::fmt::Debug::fmt(&self.0, f)
						}
					}

					impl AstToken for #ident {
						fn can_cast(kind: SyntaxKind) -> bool {
							kind == SyntaxKind::#ident
						}

						fn cast(tok: SyntaxToken) -> Option<Self> {
							if Self::can_cast(tok.kind()) {
								Some(Self(tok))
							} else {
								None
							}
						}
					}
				}
			})
			.collect();
	}

	fn gen_ast(&mut self) {
		self.nodes = Vec::with_capacity(self.grammar.iter().count());

		for node in self.grammar.iter() {
			let node = &self.grammar[node];
			let ident = format_ident!("{}", &node.name);
			self.make_node(ident, &node.rule);
		}
	}

	fn make_node(&mut self, ident: Ident, rule: &Rule) {
		let node = match rule {
			Rule::Alt(opts) => return self.make_enum(ident, opts),
			_ => {
				let mut getters = Vec::new();
				self.make_getter(rule, &mut getters, false);

				quote! {
					#[derive(Clone, PartialEq, Eq, Hash)]
					pub struct #ident(SyntaxNode);

					impl std::fmt::Debug for #ident {
						fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
							std::fmt::Debug::fmt(&self.0, f)
						}
					}

					impl AstNode for #ident {
						fn can_cast(kind: SyntaxKind) -> bool {
							kind == SyntaxKind::#ident
						}

						fn cast(node: SyntaxNode) -> Option<Self> {
							if Self::can_cast(node.kind()) {
								Some(Self(node))
							} else {
								None
							}
						}
					}

					impl #ident {
						#(#getters)*
					}
				}
			},
		};
		self.nodes.push(node);
	}

	fn make_getter(&mut self, rule: &Rule, out: &mut Vec<TokenStream>, rep: bool) {
		if self.make_comma_list(rule, out) {
			return;
		}

		match rule {
			Rule::Labeled { label, rule } => {
				let ident = format_ident!("{}", to_snake_case(label));
				let (body, ty) = self.make_getter_body(rule, rep);
				out.push(quote! {
					pub fn #ident(&self) -> #ty {
						#body
					}
				});
			},
			Rule::Node(node) => {
				let name = &self.grammar[*node].name;
				let fn_name = format_ident!("{}", to_snake_case(name));

				let (body, ty) = self.make_getter_body(rule, rep);
				out.push(quote! {
					pub fn #fn_name(&self) -> #ty {
						#body
					}
				})
			},
			Rule::Token(tok) => {
				let name = &self.grammar[*tok].name;
				let fn_name = format_ident!("{}", to_snake_case(&map_token(name)));

				let (body, ty) = self.make_getter_body(rule, rep);
				out.push(quote! {
					pub fn #fn_name(&self) -> #ty {
						#body
					}
				})
			},
			Rule::Seq(rules) => {
				for rule in rules {
					self.make_getter(rule, out, false);
				}
			},
			Rule::Opt(rule) => self.make_getter(rule, out, false),
			Rule::Rep(rule) => self.make_getter(rule, out, true),
			_ => panic!("unexpected {}", format_rule(rule, self.grammar)),
		}
	}

	fn make_getter_body(&mut self, rule: &Rule, rep: bool) -> (TokenStream, TokenStream) {
		match rule {
			Rule::Node(node) => {
				let ty = format_ident!("{}", self.grammar[*node].name);
				if rep {
					(
						quote! { node_children(&self.0) },
						quote! { impl Iterator<Item = #ty> + '_ },
					)
				} else {
					(quote! { node(&self.0) }, quote! { Option<#ty> })
				}
			},
			Rule::Token(tok) => {
				let ty = format_ident!("{}", map_token(&self.grammar[*tok].name));
				if rep {
					(
						quote! { token_children(&self.0) },
						quote! { impl Iterator<Item = #ty> + '_ },
					)
				} else {
					(quote! { token(&self.0) }, quote! { Option<#ty> })
				}
			},
			Rule::Opt(v) => self.make_getter_body(v, false),
			Rule::Rep(v) => self.make_getter_body(v, true),
			Rule::Labeled { .. } => panic!("labeled rule in getter"),
			_ => panic!("unexpected {}", format_rule(rule, self.grammar)),
		}
	}

	// (T (',' T)* ','?)
	// Stolen from rust-analyzer
	fn make_comma_list(&mut self, rule: &Rule, out: &mut Vec<TokenStream>) -> bool {
		let rule = match rule {
			Rule::Seq(it) => it,
			_ => return false,
		};
		let (node, repeat, trailing_comma) = match rule.as_slice() {
			[Rule::Node(node), Rule::Rep(repeat), Rule::Opt(trailing_comma)] => (node, repeat, trailing_comma),
			_ => return false,
		};
		let repeat = match &**repeat {
			Rule::Seq(it) => it,
			_ => return false,
		};
		match repeat.as_slice() {
			[comma, Rule::Node(n)] if comma == &**trailing_comma && n == node => (),
			_ => return false,
		}
		let ty = &self.grammar[*node].name;
		let name = format_ident!("{}", pluralize(&to_snake_case(&ty)));
		let ty = format_ident!("{}", ty);

		out.push(quote! {
			pub fn #name(&self) -> impl Iterator<Item = #ty> + '_ {
				node_children(&self.0)
			}
		});

		true
	}

	fn make_enum(&mut self, ident: Ident, opts: &Vec<Rule>) {
		let mut node_variants = Vec::new();
		let mut token_variants = Vec::new();
		for rule in opts.iter() {
			match rule {
				Rule::Node(node) => node_variants.push(format_ident!("{}", &self.grammar[*node].name)),
				Rule::Token(tok) => token_variants.push(format_ident!("{}", map_token(&self.grammar[*tok].name))),
				_ => {
					panic!("{} unexpected in 'or' pattern", format_rule(rule, self.grammar));
				},
			}
		}

		let ret = quote! {
			#[derive(Clone, PartialEq, Eq, Hash)]
			pub enum #ident {
				#(#token_variants(#token_variants),)*
				#(#node_variants(#node_variants),)*
			}

			impl std::fmt::Debug for #ident {
				fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
					match self {
						#(Self::#token_variants(x) => std::fmt::Debug::fmt(x, f),)*
						#(Self::#node_variants(x) => std::fmt::Debug::fmt(x, f),)*
					}
				}
			}

			impl AstNode for #ident {
				fn can_cast(kind: SyntaxKind) -> bool {
					kind == SyntaxKind::#ident
				}

				fn cast(node: SyntaxNode) -> Option<Self> {
					if Self::can_cast(node.kind()) {
						node.children_with_tokens().find_map(|x| match x {
							SyntaxElementRef::Node(node) => match node.kind() {
								#(SyntaxKind::#node_variants => #node_variants::cast(node.clone()).map(Self::#node_variants),)*
								_ => None,
							},
							SyntaxElementRef::Token(tok) => match tok.kind() {
								#(SyntaxKind::#token_variants => #token_variants::cast(tok.clone()).map(Self::#token_variants),)*
								_ => None,
							},
						})
					} else {
						None
					}
				}
			}
		};
		self.nodes.push(ret);
	}
}

fn map_token(x: &str) -> String {
	match x {
		// Lexer tokens
		"bool" => "BoolLit".to_string(),
		"char" => "CharLit".to_string(),
		"float" => "FloatLit".to_string(),
		"int" => "IntLit".to_string(),
		"string" => "StringLit".to_string(),
		"ident" => "Ident".to_string(),
		"@" => "At".to_string(),
		"(" => "LParen".to_string(),
		"{" => "LBrace".to_string(),
		"[" => "LBracket".to_string(),
		")" => "RParen".to_string(),
		"}" => "RBrace".to_string(),
		"]" => "RBracket".to_string(),
		"=" => "Eq".to_string(),
		"." => "Dot".to_string(),
		"*" => "Star".to_string(),
		":" => "Colon".to_string(),
		"," => "Comma".to_string(),
		";" => "Semi".to_string(),
		"->" => "Arrow".to_string(),
		"=>" => "FatArrow".to_string(),
		"_" => "Underscore".to_string(),
		"op" => "Operator".to_string(),
		x => {
			let mut s = String::with_capacity(x.len() + 2);
			s.push_str(&x[0..1].to_ascii_uppercase());
			s.push_str(&x[1..]);
			s.push_str("Kw");
			s
		},
	}
}

fn to_snake_case(x: &str) -> String {
	const RUST_KEYWORDS: &[&str] = &[
		"abstract", "alignof", "as", "become", "box", "break", "const", "continue", "crate", "do", "else", "enum",
		"extern", "false", "final", "fn", "for", "if", "impl", "in", "let", "loop", "macro", "match", "mod", "move",
		"mut", "offsetof", "override", "priv", "proc", "pub", "pure", "ref", "return", "Self", "self", "sizeof",
		"static", "struct", "super", "trait", "true", "type", "typeof", "unsafe", "unsized", "use", "virtual", "where",
		"while", "yield",
	];

	let mut s = String::with_capacity(x.len());
	let mut last = '_';
	for c in x.chars() {
		if c.is_ascii_uppercase() {
			if last != '_' {
				s.push('_');
			}
			s.push(c.to_ascii_lowercase());
		} else {
			s.push(c);
		}
		last = c;
	}

	if RUST_KEYWORDS.contains(&s.as_str()) {
		s.push('_');
	}

	s
}

fn pluralize(x: &str) -> String {
	let mut s = String::with_capacity(x.len() + 1);
	s.push_str(x);
	if s.chars().last().unwrap() == '_' {
		s.pop();
	}
	s.push('s');
	s
}

fn format_rule<'a>(rule: &'a Rule, grammar: &'a Grammar) -> impl std::fmt::Display + 'a {
	struct Fmt<'a> {
		rule: &'a Rule,
		grammar: &'a Grammar,
	}

	impl std::fmt::Display for Fmt<'_> {
		fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
			match self.rule {
				Rule::Labeled { label, rule } => write!(f, "{}:{}", label, format_rule(rule, self.grammar)),
				Rule::Node(node) => write!(f, "{}", self.grammar[*node].name),
				Rule::Token(tok) => write!(f, "'{}'", self.grammar[*tok].name),
				Rule::Seq(seq) => {
					write!(f, "(")?;
					for rule in seq {
						write!(f, "{} ", format_rule(rule, self.grammar))?;
					}
					write!(f, ")")
				},
				Rule::Alt(opts) => {
					write!(f, "(")?;
					for rule in opts {
						write!(f, "{} | ", format_rule(rule, self.grammar))?;
					}
					write!(f, ")")
				},
				Rule::Opt(v) => {
					write!(f, "{}?", format_rule(v, self.grammar))
				},
				Rule::Rep(v) => {
					write!(f, "{}*", format_rule(v, self.grammar))
				},
			}
		}
	}

	Fmt { rule, grammar }
}

fn write(file: PathBuf, contents: String) {
	std::fs::write(&file, contents).unwrap();
	format(&file);
}

fn format(file: &Path) { Command::new("rustfmt").arg(file).status().unwrap(); }
